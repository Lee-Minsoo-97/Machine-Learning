{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Minsoo-97/Machine-Learning/blob/main/5_Different_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbQdn06JyBqD"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', None)  # Display all rows\n",
        "pd.set_option('display.max_columns', None)  # Display all columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU21Wd4Oy70P"
      },
      "outputs": [],
      "source": [
        "path_train = \"/content/drive/MyDrive/Colab Notebooks/CIS508_Machine_Learning/Individual_Assignment/train.csv\"\n",
        "path_test = \"/content/drive/MyDrive/Colab Notebooks/CIS508_Machine_Learning/Individual_Assignment/test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(path_train)\n",
        "test_df = pd.read_csv(path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQyYYL5hE-6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ac0faf-7014-42c6-9e9d-ff1d48dc8a21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['QuoteNumber', 'Original_Quote_Date', 'QuoteConversion_Flag', 'Field6',\n",
              "       'Field7', 'Field8', 'Field9', 'Field10', 'Field11', 'Field12',\n",
              "       ...\n",
              "       'GeographicField59A', 'GeographicField59B', 'GeographicField60A',\n",
              "       'GeographicField60B', 'GeographicField61A', 'GeographicField61B',\n",
              "       'GeographicField62A', 'GeographicField62B', 'GeographicField63',\n",
              "       'GeographicField64'],\n",
              "      dtype='object', length=299)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3ylVMT5FCc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8109bcba-dae6-423a-d79c-36d423ad6fe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['QuoteNumber', 'Original_Quote_Date', 'Field6', 'Field7', 'Field8',\n",
              "       'Field9', 'Field10', 'Field11', 'Field12', 'CoverageField1A',\n",
              "       ...\n",
              "       'GeographicField59A', 'GeographicField59B', 'GeographicField60A',\n",
              "       'GeographicField60B', 'GeographicField61A', 'GeographicField61B',\n",
              "       'GeographicField62A', 'GeographicField62B', 'GeographicField63',\n",
              "       'GeographicField64'],\n",
              "      dtype='object', length=298)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoYHSn7lS14Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Drop unnecessary columns\n",
        "train_df = train_df.drop(columns=[\"QuoteNumber\", \"Original_Quote_Date\"])\n",
        "test_df = test_df.drop(columns=[\"QuoteNumber\", \"Original_Quote_Date\"])\n",
        "\n",
        "# Align train and test columns\n",
        "common_columns = list(set(train_df.columns) & set(test_df.columns))\n",
        "train_df = train_df[common_columns + [\"QuoteConversion_Flag\"]]\n",
        "test_df = test_df[common_columns]\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=[\"QuoteConversion_Flag\"])\n",
        "y = train_df[\"QuoteConversion_Flag\"]\n",
        "\n",
        "# Handle missing values\n",
        "numerical_imputer = SimpleImputer(strategy=\"mean\")\n",
        "categorical_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
        "\n",
        "categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
        "numerical_columns = X.select_dtypes(exclude=[\"object\"]).columns\n",
        "\n",
        "X[categorical_columns] = X[categorical_columns].astype(str)\n",
        "test_df[categorical_columns] = test_df[categorical_columns].astype(str)\n",
        "\n",
        "X[numerical_columns] = numerical_imputer.fit_transform(X[numerical_columns])\n",
        "test_df[numerical_columns] = numerical_imputer.transform(test_df[numerical_columns])\n",
        "\n",
        "X[categorical_columns] = categorical_imputer.fit_transform(X[categorical_columns])\n",
        "test_df[categorical_columns] = categorical_imputer.transform(test_df[categorical_columns])\n",
        "\n",
        "# Encode categorical and scale numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_columns),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57nV-HNua0_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea62d52-59aa-45fc-bbd0-13a044ce6c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE applied successfully.\n"
          ]
        }
      ],
      "source": [
        "X_processed = preprocessor.fit_transform(X)\n",
        "test_processed = preprocessor.transform(test_df)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_processed, y)\n",
        "\n",
        "print(\"SMOTE applied successfully.\")\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Dictionary to store results\n",
        "model_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRad97ZRc3zq"
      },
      "outputs": [],
      "source": [
        "# Function to train a model and calculate AUC\n",
        "def train_model(model, model_name):\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    train_pred = model.predict_proba(X_train)[:, 1]\n",
        "    val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    test_pred = model.predict_proba(test_processed)[:, 1]\n",
        "\n",
        "    # Store results\n",
        "    model_results[model_name] = {\n",
        "        \"Train AUC\": roc_auc_score(y_train, train_pred),\n",
        "        \"Validation AUC\": roc_auc_score(y_val, val_pred),\n",
        "        \"Test Predictions\": test_pred\n",
        "    }\n",
        "    print(f\"{model_name} - Train AUC: {model_results[model_name]['Train AUC']:.4f}, \"\n",
        "          f\"Validation AUC: {model_results[model_name]['Validation AUC']:.4f}\")\n",
        "    return train_pred, val_pred, test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73Z3zSCYc4PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0291e71-c78a-4114-bbf9-582a954a10d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Decision Tree...\n",
            "Decision Tree - Train AUC: 0.9839, Validation AUC: 0.9833\n"
          ]
        }
      ],
      "source": [
        "# Train models\n",
        "dt_train, dt_val, dt_test = train_model(\n",
        "    DecisionTreeClassifier(random_state=42, max_depth=10), \"Decision Tree\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u7hVLGtosoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912c2c7f-74df-4831-ea86-d77c256d5a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Random Forest - Train AUC: 1.0000, Validation AUC: 0.9910\n"
          ]
        }
      ],
      "source": [
        "rf_train, rf_val, rf_test = train_model(\n",
        "    RandomForestClassifier(random_state=42, n_estimators=50, n_jobs=-1), \"Random Forest\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 데이터 샘플링\n",
        "sample_size = 10000\n",
        "X_train_sample = X_train[:sample_size]\n",
        "y_train_sample = y_train[:sample_size]\n",
        "\n",
        "# PCA 차원 축소\n",
        "pca = PCA(n_components=100, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_sample)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "test_processed_pca = pca.transform(test_processed)\n",
        "\n",
        "# SVM 실행\n",
        "print(\"Training Optimized Support Vector Machines...\")\n",
        "optimized_svm = SVC(probability=True, random_state=42, kernel='linear', max_iter=200)\n",
        "optimized_svm.fit(X_train_pca, y_train_sample)\n",
        "\n",
        "# 예측 생성\n",
        "svm_train_pred = optimized_svm.predict_proba(X_train_pca)[:, 1]\n",
        "svm_val_pred = optimized_svm.predict_proba(X_val_pca)[:, 1]\n",
        "svm_test_pred = optimized_svm.predict_proba(test_processed_pca)[:, 1]\n",
        "\n",
        "# AUC 계산\n",
        "train_auc = roc_auc_score(y_train_sample, svm_train_pred)\n",
        "val_auc = roc_auc_score(y_val, svm_val_pred)\n",
        "print(f\"Optimized SVM - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")"
      ],
      "metadata": {
        "id": "UbMK4qEhJw8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c0b839-4b8e-4dee-8a38-d983cccb67b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Optimized Support Vector Machines...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized SVM - Train AUC: 0.6013, Validation AUC: 0.6069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHN7Tm5YtWtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e1e075-15d8-4b62-9f99-6a82fd7c2875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Optimized Multilayer Perceptron...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized MLP - Train AUC: 0.9770, Validation AUC: 0.9760\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA 차원 축소 (100개 주요 성분만 유지)\n",
        "pca = PCA(n_components=100, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "test_processed_pca = pca.transform(test_processed)\n",
        "\n",
        "# 최적화된 MLP\n",
        "print(\"Training Optimized Multilayer Perceptron...\")\n",
        "optimized_mlp = MLPClassifier(\n",
        "    random_state=42,\n",
        "    max_iter=100,              # 반복 횟수 제한\n",
        "    hidden_layer_sizes=(20, 10),  # 작은 히든 레이어\n",
        "    learning_rate_init=0.01,   # 초기 학습률 증가\n",
        "    solver='adam',             # 기본 solver 유지\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "optimized_mlp.fit(X_train_pca, y_train)\n",
        "\n",
        "# 예측 생성\n",
        "mlp_train_pred = optimized_mlp.predict_proba(X_train_pca)[:, 1]\n",
        "mlp_val_pred = optimized_mlp.predict_proba(X_val_pca)[:, 1]\n",
        "mlp_test_pred = optimized_mlp.predict_proba(test_processed_pca)[:, 1]\n",
        "\n",
        "# AUC 계산\n",
        "train_auc = roc_auc_score(y_train, mlp_train_pred)\n",
        "val_auc = roc_auc_score(y_val, mlp_val_pred)\n",
        "print(f\"Optimized MLP - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxdZr8WztX_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79aa3969-1e8f-450c-cb3e-3038abc84a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Optimized K-Nearest Neighbors...\n",
            "Optimized KNN - Train AUC: 0.9434, Validation AUC: 0.7774\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 데이터 크기 줄이기 (10,000개 샘플만 사용)\n",
        "sample_size = 10000\n",
        "X_train_sample = X_train[:sample_size]\n",
        "y_train_sample = y_train[:sample_size]\n",
        "\n",
        "# PCA 차원 축소 (50개 주요 성분만 유지)\n",
        "pca = PCA(n_components=50, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_sample)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "test_processed_pca = pca.transform(test_processed)\n",
        "\n",
        "# 최적화된 KNN\n",
        "print(\"Training Optimized K-Nearest Neighbors...\")\n",
        "optimized_knn = KNeighborsClassifier(\n",
        "    n_neighbors=3,   # 이웃 수 줄이기\n",
        "    metric='manhattan'  # 계산이 간단한 거리 측정 방식\n",
        ")\n",
        "\n",
        "# KNN 모델 학습\n",
        "optimized_knn.fit(X_train_pca, y_train_sample)\n",
        "\n",
        "# 예측 생성\n",
        "knn_train_pred = optimized_knn.predict_proba(X_train_pca)[:, 1]\n",
        "knn_val_pred = optimized_knn.predict_proba(X_val_pca)[:, 1]\n",
        "knn_test_pred = optimized_knn.predict_proba(test_processed_pca)[:, 1]\n",
        "\n",
        "# AUC 계산\n",
        "train_auc = roc_auc_score(y_train_sample, knn_train_pred)\n",
        "val_auc = roc_auc_score(y_val, knn_val_pred)\n",
        "print(f\"Optimized KNN - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이 확인\n",
        "print(f\"Decision Tree Train Length: {len(dt_train)}\")\n",
        "print(f\"Random Forest Train Length: {len(rf_train)}\")\n",
        "print(f\"SVM Train Length: {len(svm_train_pred)}\")\n",
        "print(f\"MLP Train Length: {len(mlp_train_pred)}\")\n",
        "print(f\"KNN Train Length: {len(knn_train_pred)}\")\n",
        "\n",
        "# 배열 길이 강제 정렬\n",
        "min_length = min(len(dt_train), len(rf_train), len(svm_train_pred), len(mlp_train_pred), len(knn_train_pred))\n",
        "dt_train = dt_train[:min_length]\n",
        "rf_train = rf_train[:min_length]\n",
        "svm_train_pred = svm_train_pred[:min_length]\n",
        "mlp_train_pred = mlp_train_pred[:min_length]\n",
        "knn_train_pred = knn_train_pred[:min_length]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNsL6townxkX",
        "outputId": "07fc7bbf-293b-4425-cfb5-f47f5af59661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Train Length: 338974\n",
            "Random Forest Train Length: 338974\n",
            "SVM Train Length: 10000\n",
            "MLP Train Length: 338974\n",
            "KNN Train Length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# 스태킹 피처 생성\n",
        "stacking_features_train = pd.DataFrame({\n",
        "    \"Decision Tree\": dt_train,\n",
        "    \"Random Forest\": rf_train,\n",
        "    \"Support Vector Machines\": svm_train_pred,\n",
        "    \"Multilayer Perceptron\": mlp_train_pred,\n",
        "    \"K-Nearest Neighbors\": knn_train_pred\n",
        "})\n",
        "\n",
        "stacking_features_val = pd.DataFrame({\n",
        "    \"Decision Tree\": dt_val,\n",
        "    \"Random Forest\": rf_val,\n",
        "    \"Support Vector Machines\": svm_val_pred,\n",
        "    \"Multilayer Perceptron\": mlp_val_pred,\n",
        "    \"K-Nearest Neighbors\": knn_val_pred\n",
        "})\n",
        "\n",
        "stacking_features_test = pd.DataFrame({\n",
        "    \"Decision Tree\": dt_test,\n",
        "    \"Random Forest\": rf_test,\n",
        "    \"Support Vector Machines\": svm_test_pred,\n",
        "    \"Multilayer Perceptron\": mlp_test_pred,\n",
        "    \"K-Nearest Neighbors\": knn_test_pred\n",
        "})\n",
        "\n"
      ],
      "metadata": {
        "id": "Piz2w_PyKYbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 테스트 데이터 불러오기\n",
        "original_test_df = pd.read_csv(path_test)\n",
        "\n",
        "# 복구된 QuoteNumber를 test_df에 추가\n",
        "test_df[\"QuoteNumber\"] = original_test_df[\"QuoteNumber\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Tn-qFxqkei",
        "outputId": "dda40bac-e985-4911-8d52-9683ecc36695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-10452bd57c11>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[\"QuoteNumber\"] = original_test_df[\"QuoteNumber\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Meta-Model with sampled data\n",
        "print(\"Training Meta-Model (Logistic Regression)...\")\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "meta_model.fit(stacking_features_train, y_train_sample)  # 샘플링된 y_train 사용\n",
        "\n",
        "# Evaluate Meta-Model\n",
        "stacked_val_predictions = meta_model.predict_proba(stacking_features_val)[:, 1]\n",
        "stacked_test_predictions = meta_model.predict_proba(stacking_features_test)[:, 1]\n",
        "\n",
        "# Calculate Validation AUC for Meta-Model\n",
        "stacked_val_auc = roc_auc_score(y_val, stacked_val_predictions)\n",
        "print(f\"Stacked Model - Validation AUC: {stacked_val_auc:.4f}\")\n",
        "\n",
        "# Save Submission File\n",
        "submission = pd.DataFrame({\n",
        "    \"QuoteNumber\": test_df[\"QuoteNumber\"],  # 복구된 QuoteNumber 사용\n",
        "    \"QuoteConversion_Flag\": stacked_test_predictions\n",
        "})\n",
        "submission.to_csv(\"Stacked_Model_submission.csv\", index=False)\n",
        "print(\"Stacked model submission file created.\")\n"
      ],
      "metadata": {
        "id": "T4USEf9zKaQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3a595c-c01a-4eb5-d07a-abfb91e9cb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Meta-Model (Logistic Regression)...\n",
            "Stacked Model - Validation AUC: 0.9906\n",
            "Stacked model submission file created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k2-fKi8RqaEm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1m1c0H78TelcCOtpWY797isajGl6DqnZc",
      "authorship_tag": "ABX9TyO+nVWwgrWfIGtYLxBHPFPB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}