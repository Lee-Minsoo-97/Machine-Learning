{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHM/Kj2+6f5TkJ+w+RutlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Minsoo-97/Machine-Learning/blob/main/Decision_Tree_%26_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier"
      ],
      "metadata": {
        "id": "R9OxbsDnNOyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk6V3dlXHt-l"
      },
      "outputs": [],
      "source": [
        "#install\n",
        "#!pip install scikit-optimize\n",
        "# Data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Model building\n",
        "from skopt.space import Integer, Categorical\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from skopt import BayesSearchCV  # Bayesian optimization\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Other\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lini to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K7unloiJcZB",
        "outputId": "cc350bab-d3f4-4992-8291-cc35e6c83664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "path_train = '/content/drive/MyDrive/Colab Notebooks/CIS508_Machine_Learning/Individual_Assignment/Insurance Fraud - TRAIN-3000.csv'\n",
        "path_test = '/content/drive/MyDrive/Colab Notebooks/CIS508_Machine_Learning/Individual_Assignment/Insurance Fraud -TEST-12900.csv'\n",
        "\n",
        "df_train = pd.read_csv(path_train)\n",
        "df_test = pd.read_csv(path_test)\n",
        "\n",
        "# Separate features and target in the training data\n",
        "X_train = df_train.drop(\"FRAUDFOUND\", axis=1)\n",
        "y_train = df_train[\"FRAUDFOUND\"]\n",
        "\n",
        "# Apply the same transformation to the test data\n",
        "X_test = df_test.drop(\"FRAUDFOUND\", axis=1)\n",
        "y_test = df_test[\"FRAUDFOUND\"]\n",
        "\n",
        "# Encoding categorical variables\n",
        "categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Align test and train data (if they have different columns after encoding)\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "# Convert Target Labels to Numeric\n",
        "y_train = y_train.map({'No': 0, 'Yes': 1})\n",
        "y_test = y_test.map({'No': 0, 'Yes': 1})\n"
      ],
      "metadata": {
        "id": "bxMzimcmJ9uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to balance the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "dIv1YF4BKWrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42,class_weight='balanced')\n",
        "\n",
        "# Expanded hyperparameter grid\n",
        "dt_param_grid_expanded = {\n",
        "    'max_depth': range(1, 51, 10),                   # Increased range with steps to reduce combinations\n",
        "    'min_samples_split': range(2, 21, 2),            # Wider range to explore split sizes\n",
        "    'min_samples_leaf': range(1, 11, 2),             # Control minimum samples at leaf\n",
        "    'criterion': ['gini', 'entropy'],                # Split quality criteria\n",
        "    'max_features': ['auto', 'sqrt', 'log2']         # Feature subset at each split\n",
        "}"
      ],
      "metadata": {
        "id": "rrpcCyV7KpTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Grid Search with expanded grid (may take longer time due to combinatorial growth)\n",
        "grid_search_dt_expanded = GridSearchCV(estimator=dt, param_grid=dt_param_grid_expanded, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search_dt_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Decision Tree - Expanded Grid Search Best Parameters:\", grid_search_dt_expanded.best_params_)\n",
        "\n",
        "# Random Search with expanded grid (limited by n_iter to control runtime)\n",
        "random_search_dt_expanded = RandomizedSearchCV(estimator=dt, param_distributions=dt_param_grid_expanded, cv=5, n_iter=20, scoring='f1', random_state=42, n_jobs=-1)\n",
        "random_search_dt_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Decision Tree - Expanded Random Search Best Parameters:\", random_search_dt_expanded.best_params_)\n",
        "\n",
        "# Corrected expanded hyperparameter grid for Bayesian Search\n",
        "bayes_param_grid_expanded = {\n",
        "    'max_depth': Integer(1, 50),\n",
        "    'min_samples_split': Integer(2, 20),\n",
        "    'min_samples_leaf': Integer(1, 10),\n",
        "    'criterion': Categorical(['gini', 'entropy']),\n",
        "    'max_features': Categorical(['sqrt', 'log2', None])  # Remove 'auto' as it's invalid for DecisionTreeClassifier\n",
        "}\n",
        "\n",
        "# Bayesian Search with corrected grid\n",
        "bayes_search_dt_expanded = BayesSearchCV(estimator=dt, search_spaces=bayes_param_grid_expanded, cv=5, scoring='f1', n_iter=30, random_state=42, n_jobs=-1)\n",
        "bayes_search_dt_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Decision Tree - Expanded Bayesian Search Best Parameters:\", bayes_search_dt_expanded.best_params_)"
      ],
      "metadata": {
        "id": "zbvcrGKbK7cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6795ce17-67a9-4253-94fc-7d0d90e9cc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Expanded Grid Search Best Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 6}\n",
            "Decision Tree - Expanded Random Search Best Parameters: {'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 21, 'criterion': 'entropy'}\n",
            "Decision Tree - Expanded Bayesian Search Best Parameters: OrderedDict([('criterion', 'gini'), ('max_depth', 27), ('max_features', None), ('min_samples_leaf', 1), ('min_samples_split', 2)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models with best parameters from each search\n",
        "# Expanded Grid Search Model\n",
        "dt_grid_expanded = DecisionTreeClassifier(**grid_search_dt_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "dt_grid_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Expanded Random Search Model\n",
        "dt_random_expanded = DecisionTreeClassifier(**random_search_dt_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "dt_random_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Expanded Bayesian Search Model\n",
        "dt_bayes_expanded = DecisionTreeClassifier(**bayes_search_dt_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "dt_bayes_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Function to evaluate model on the test set\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    results = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred)\n",
        "    }\n",
        "    return results\n",
        "\n",
        "# Evaluate each model on the test set\n",
        "print(\"Evaluating Expanded Grid Search Model\")\n",
        "grid_results_expanded = evaluate_model(dt_grid_expanded, X_test, y_test)\n",
        "\n",
        "print(\"Evaluating Expanded Random Search Model\")\n",
        "random_results_expanded = evaluate_model(dt_random_expanded, X_test, y_test)\n",
        "\n",
        "print(\"Evaluating Expanded Bayesian Search Model\")\n",
        "bayes_results_expanded = evaluate_model(dt_bayes_expanded, X_test, y_test)\n",
        "\n",
        "# Compile and display results for comparison\n",
        "comparison_df_expanded = pd.DataFrame([grid_results_expanded, random_results_expanded, bayes_results_expanded],\n",
        "                                      index=[\"Expanded Grid Search\", \"Expanded Random Search\", \"Expanded Bayesian Search\"])\n",
        "print(\"\\nComparison of Decision Tree Classifiers with Expanded Grid:\")\n",
        "print(comparison_df_expanded)\n"
      ],
      "metadata": {
        "id": "sOIcZN8HMLGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6b1b34-478e-4363-c881-9e15cbe70c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Expanded Grid Search Model\n",
            "Evaluating Expanded Random Search Model\n",
            "Evaluating Expanded Bayesian Search Model\n",
            "\n",
            "Comparison of Decision Tree Classifiers with Expanded Grid:\n",
            "                          Accuracy  Precision    Recall  F1 Score\n",
            "Expanded Grid Search      0.859421   0.157128  0.606426  0.249587\n",
            "Expanded Random Search    0.858956   0.140608  0.520080  0.221368\n",
            "Expanded Bayesian Search  0.864453   0.207653  0.893574  0.336994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "•\tWhy 1 to 20? This range is typically a good starting point for tuning. In practice, trees deeper than 20 tend to overfit unless you have a large, complex dataset. If your data is simpler or you find overfitting, you might reduce the upper limit.\n",
        "\n",
        "\n",
        "•\tWhy 2 to 10? This range provides flexibility from a highly detailed tree (min_samples_split=2) to a simpler, generalized tree. It’s common to start with 2 and test up to around 10, but the range can be adjusted based on data size and noise levels."
      ],
      "metadata": {
        "id": "y-rvloSYSNqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranodm Forest Classifier"
      ],
      "metadata": {
        "id": "MU1nHuTZgk-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Expanded hyperparameter grid for RandomForestClassifier\n",
        "# Adjusted hyperparameter grid for RandomForestClassifier\n",
        "rf_param_grid_expanded = {\n",
        "    'n_estimators': [50, 100, 200],            # Reduced number of trees\n",
        "    'max_depth': [10, 20, 30],                 # Fewer values for depth\n",
        "    'min_samples_split': [2, 10, 20],          # Limited split options\n",
        "    'min_samples_leaf': [1, 5, 10],            # Limited leaf options\n",
        "    'criterion': ['gini', 'entropy'],          # Criterion for split quality\n",
        "    'max_features': ['auto', 'sqrt', 'log2']   # Valid options for RandomForestClassifier\n",
        "}"
      ],
      "metadata": {
        "id": "l4xKiDZ9SzfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest with class_weight='balanced'\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Grid Search with expanded grid\n",
        "grid_search_rf_expanded = GridSearchCV(estimator=rf, param_grid=rf_param_grid_expanded, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_search_rf_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Random Forest - Expanded Grid Search Best Parameters:\", grid_search_rf_expanded.best_params_)\n",
        "\n",
        "# Random Search with expanded grid\n",
        "random_search_rf_expanded = RandomizedSearchCV(estimator=rf, param_distributions=rf_param_grid_expanded, cv=3, n_iter=10, scoring='f1', random_state=42, n_jobs=-1)\n",
        "random_search_rf_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Random Forest - Expanded Random Search Best Parameters:\", random_search_rf_expanded.best_params_)\n"
      ],
      "metadata": {
        "id": "sIV1Sl1GSzdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "collapsed": true,
        "outputId": "0ba52252-cc05-46f2-be08-d92ba3fd2062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Expanded Grid Search Best Parameters: {'criterion': 'gini', 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Random Forest - Expanded Random Search Best Parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidParameterError",
          "evalue": "The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-ad24439f91f3>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Bayesian Search with expanded grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mbayes_search_rf_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbayes_rf_param_grid_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mbayes_search_rf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest - Expanded Bayesian Search Best Parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_search_rf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    540\u001b[0m             )\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                 optim_result, score_name = self._step(\n\u001b[0m\u001b[1;32m    600\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# if self.scoring is a callable, we have to wait until here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Forest - Expanded Grid Search Best Parameters:\", grid_search_rf_expanded.best_params_)\n",
        "print(\"Random Forest - Expanded Random Search Best Parameters:\", random_search_rf_expanded.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVPAS30yckWm",
        "outputId": "bff0d8fb-8bce-415f-c084-da2c0cd292ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Expanded Grid Search Best Parameters: {'criterion': 'gini', 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Random Forest - Expanded Random Search Best Parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_rf_param_grid_expanded = {\n",
        "    'n_estimators': Integer(50, 300),\n",
        "    'max_depth': Integer(10, 50),\n",
        "    'min_samples_split': Integer(2, 20),\n",
        "    'min_samples_leaf': Integer(1, 10),\n",
        "    'criterion': Categorical(['gini', 'entropy']),\n",
        "    'max_features': Categorical(['sqrt', 'log2', None])  # Replace 'auto' with None\n",
        "}\n",
        "\n",
        "# Bayesian Search with corrected grid\n",
        "bayes_search_rf_expanded = BayesSearchCV(estimator=rf, search_spaces=bayes_rf_param_grid_expanded, cv=3, scoring='f1', n_iter=15, random_state=42, n_jobs=-1)\n",
        "bayes_search_rf_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Random Forest - Expanded Bayesian Search Best Parameters:\", bayes_search_rf_expanded.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ahKHzrce2A",
        "outputId": "3321332a-321e-4236-bda4-7219e338d1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Expanded Bayesian Search Best Parameters: OrderedDict([('criterion', 'gini'), ('max_depth', 50), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 18), ('n_estimators', 231)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models with best parameters from each search method\n",
        "# Grid Search Model\n",
        "rf_grid_expanded = RandomForestClassifier(**grid_search_rf_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "rf_grid_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Random Search Model\n",
        "rf_random_expanded = RandomForestClassifier(**random_search_rf_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "rf_random_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Bayesian Search Model\n",
        "rf_bayes_expanded = RandomForestClassifier(**bayes_search_rf_expanded.best_params_, random_state=42, class_weight='balanced')\n",
        "rf_bayes_expanded.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Evaluate each model on the test set\n",
        "print(\"Evaluating Expanded Grid Search Model\")\n",
        "grid_results_rf_expanded = evaluate_model(rf_grid_expanded, X_test, y_test)\n",
        "\n",
        "print(\"Evaluating Expanded Random Search Model\")\n",
        "random_results_rf_expanded = evaluate_model(rf_random_expanded, X_test, y_test)\n",
        "\n",
        "print(\"Evaluating Expanded Bayesian Search Model\")\n",
        "bayes_results_rf_expanded = evaluate_model(rf_bayes_expanded, X_test, y_test)\n",
        "\n",
        "# Compile and display results for comparison\n",
        "comparison_df_rf_expanded = pd.DataFrame([grid_results_rf_expanded, random_results_rf_expanded, bayes_results_rf_expanded],\n",
        "                                         index=[\"Expanded Grid Search\", \"Expanded Random Search\", \"Expanded Bayesian Search\"])\n",
        "print(\"\\nComparison of Random Forest Classifiers with Expanded Grid:\")\n",
        "print(comparison_df_rf_expanded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edij0YfF_pQ8",
        "outputId": "bd92c358-7226-4ed3-a8be-e0e45c49cd7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Expanded Grid Search Model\n",
            "Evaluating Expanded Random Search Model\n",
            "Evaluating Expanded Bayesian Search Model\n",
            "\n",
            "Comparison of Random Forest Classifiers with Expanded Grid:\n",
            "                          Accuracy  Precision    Recall  F1 Score\n",
            "Expanded Grid Search      0.947205   0.410680  0.849398  0.553665\n",
            "Expanded Random Search    0.932265   0.323336  0.692771  0.440895\n",
            "Expanded Bayesian Search  0.934742   0.297297  0.508032  0.375093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_muKuYmadNYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9c-xjx-piX3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiHe8NMoj01Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}